

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  
  <!-- Licensed under the Apache 2.0 License -->
  <link rel="stylesheet" type="text/css" href="../_static/fonts/open-sans/stylesheet.css" />
  <!-- Licensed under the SIL Open Font License -->
  <link rel="stylesheet" type="text/css" href="../_static/fonts/source-serif-pro/source-serif-pro.css" />
  <link rel="stylesheet" type="text/css" href="../_static/css/bootstrap.min.css" />
  <link rel="stylesheet" type="text/css" href="../_static/css/bootstrap-theme.min.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
    <title>Accelerating simulations with GPUs &#8212; Nengo 1.4 1.4 documentation</title>
    <link rel="stylesheet" href="../_static/guzzle.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '1.4',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Integrating with IPython Notebook" href="ipython_notebook.html" />
    <link rel="prev" title="Generating large ensembles" href="large_ensembles.html" />
<link rel="stylesheet" type="text/css" href="../_static/custom.css">


  
   

  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="ipython_notebook.html" title="Integrating with IPython Notebook"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="large_ensembles.html" title="Generating large ensembles"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Nengo 1.4 1.4 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">Advanced usage</a> &#187;</li> 
      </ul>
    </div>
    <div class="container-wrapper">

      <div id="mobile-toggle">
        <a href="#"><span class="glyphicon glyphicon-align-justify" aria-hidden="true"></span></a>
      </div>
  <div id="left-column">
    <div class="sphinxsidebar">
        <a href="
    ../index.html" class="text-logo">Nengo 1.4</a>
        
<div class="sidebar-block">
  <div class="sidebar-wrapper">
    <h2>Table Of Contents</h2>
  </div>
  <div class="sidebar-toc">
    
    
      <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../videos/index.html">Video tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html">Written tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demos/index.html">Demos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scripting/index.html">Scripting</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Advanced usage</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="layout.html">Interactive plots layout files</a></li>
<li class="toctree-l2"><a class="reference internal" href="dragndrop.html">Creating a drag and drop template</a></li>
<li class="toctree-l2"><a class="reference internal" href="experiments.html">Running experiments</a></li>
<li class="toctree-l2"><a class="reference internal" href="matlab.html">Running Nengo in Matlab</a></li>
<li class="toctree-l2"><a class="reference internal" href="large_ensembles.html">Generating large ensembles</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Accelerating simulations with GPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="ipython_notebook.html">Integrating with IPython Notebook</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../nef_algorithm.html">The NEF Algorithm</a></li>
</ul>

    
  </div>
</div>
        
<div class="sidebar-block">
  <div class="sidebar-wrapper">
    <div id="main-search">
      <form class="form-inline" action="../search.html" method="GET" role="form">
        <div class="input-group">
          <input name="q" type="text" class="form-control" placeholder="Search...">
        </div>
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
      </form>
    </div>
  </div>
</div>
    </div>
  </div>
        <div id="right-column">
          
          <div role="navigation" aria-label="breadcrumbs navigation">
            <ol class="breadcrumb">
              <li><a href="../index.html">Docs</a></li>
              
                <li><a href="index.html">Advanced usage</a></li>
              
              <li>Accelerating simulations with GPUs</li>
            </ol>
          </div>
          
          <div class="document clearer body">
            
  <div class="section" id="accelerating-simulations-with-gpus">
<h1>Accelerating simulations with GPUs<a class="headerlink" href="#accelerating-simulations-with-gpus" title="Permalink to this headline">¶</a></h1>
<p>Since neurons are parallel processors,
Nengo can take advantage of the parallelization offered by GPUs
to speed up simulations.
Currently, only NEF Ensembles and NetworkArrays containing NEF Ensembles
can benefit from GPU acceleration
(and they must be composed solely of leaky integrate-and-fire (LIF) neurons).
You can still use the GPU for Networks
which contain other types of nodes,
but only nodes that meet these criteria
will actually be executed on the GPU
(the rest will run on the CPU).
This restriction is necessary because GPUs
take advantage of a computing technique called
Single-Instruction Multiple-Data,
wherein we have many instances of the same code
running on different data.
If we are only using NEF Ensembles containing LIF neurons
then we are well within this paradigm:
we want to execute many instances
of the code simulating the LIF neurons,
but each neuron has different parameters and input.
On the other hand, a SimpleNode
that you have defined yourself in a Python script
cannot run on the GPU
because SimpleNodes can contain arbitrary code.</p>
<p>The GPU can also be used to speed up
the process of creating NEF Ensembles.
The dominant component in creating an NEF Ensemble
in terms of runtime is solving for the decoders,
which requires performing Singular Value Decomposition (SVD)
on a matrix with dimensions <span class="math">\(N \times N\)</span>
where <span class="math">\(N\)</span> is the number of neurons.
If the number of neurons in the ensemble is large,
this can be an extremely computationally expensive operation.
You can use CUDA to perform this SVD operation much faster.</p>
<p>The Nengo GPU implementation requires
the CUDA developer driver and runtime libraries for your operating system.
You may also want to install the CUDA code samples,
which let you test whether your machine can access
and communicate with the GPU,
and whether the GPU is performing up to standards.
Installers for each of these can be downloaded from
<a class="reference external" href="http://developer.nvidia.com/cuda-toolkit-40">nvidia’s website</a>.
As a first step, you should download a copy of each of these.
We have tested Nengo with version 4.0 of the CUDA toolkit.
Newer versions may work, but we cannot guarantee it.</p>
<p>The SVD computation requires
a third party GPU linear algebra toolkit called CULA Dense
in addition to the CUDA toolkit.
CULA Dense can be downloaded free of charge
(though does require a quick registration)
from <a class="reference external" href="http://culatools.com/downloads/dense/">the CULA tools website</a>.
Download version R13a
as it is compatible with version 4.0 of the CUDA toolkit.
CULA is NOT required if you only want to run simulations on the GPU.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Most of the following steps have to be performed for both <em>NengoGPU</em>,
the library for running Nengo simulations on the GPU,
and <em>NengoUtilsGPU</em>, the library for performing SVD on the GPU.
Here, we detail the process of installing <em>NengoGPU</em>,
but the process of installing <em>NengoUtilsGPU</em> is almost identical.
Steps specific to installing <em>NengoUtilsGPU</em>
will be marked as optional.
The main difference is that <em>NengoUtilsGPU</em> relies on CULA
whereas <em>NengoGPU</em> has no such dependency,
and this manifests itself in several places throughout the process.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The steps below assume that you are using a Linux computer.
If you are using another operating system,
the general steps should be the same,
though the details will differ significantly.</p>
</div>
<div class="section" id="install-cuda-developer-driver">
<h2>1. Install CUDA Developer Driver<a class="headerlink" href="#install-cuda-developer-driver" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p class="first">Be sure you have downloaded the <a class="reference external" href="http://developer.nvidia.com/cuda-toolkit-40">CUDA developer driver installer</a>
for your system. Note where the file gets downloaded.</p>
</li>
<li><p class="first">In a shell, enter the command</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">sudo</span> <span class="n">gdm</span> <span class="n">service</span> <span class="n">stop</span>
</pre></div>
</div>
<p>This stops the X server.
The X server relies on the GPU driver,
so the former can’t be running
while the latter is being updated.</p>
</li>
<li><p class="first">Hit <code class="docutils literal"><span class="pre">Ctrl-Alt-F1</span></code>.
This should take you to a login shell.
Enter your credentials and then <code class="docutils literal"><span class="pre">cd</span></code> into the directory
where the driver installer was downloaded.</p>
</li>
<li><p class="first">To start the installer, run the command</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">sudo</span> <span class="n">sh</span> <span class="o">&lt;</span><span class="n">driver</span><span class="o">-</span><span class="n">installer</span><span class="o">&gt;</span>
</pre></div>
</div>
</li>
<li><p class="first">Answer yes to the queries from the installer,
especially the one that asks to change <code class="docutils literal"><span class="pre">xorg.conf</span></code>.</p>
</li>
<li><p class="first">Once installation has finished, restart the X server with</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">sudo</span> <span class="n">gdm</span> <span class="n">service</span> <span class="n">start</span>
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="install-cuda-toolkit">
<h2>2. Install CUDA Toolkit<a class="headerlink" href="#install-cuda-toolkit" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p class="first">Be sure you have downloaded the <a class="reference external" href="http://developer.nvidia.com/cuda-toolkit-40">CUDA toolkit installer</a>
for your system. Note where the file gets downloaded.</p>
</li>
<li><p class="first">Run the installer with</p>
<div class="code highlight-default"><div class="highlight"><pre><span></span><span class="n">sudo</span> <span class="n">sh</span> <span class="o">&lt;</span><span class="n">toolkit</span><span class="o">-</span><span class="n">installer</span><span class="o">&gt;</span>
</pre></div>
</div>
</li>
<li><p class="first">The installer will ask where you want to install CUDA.
The default location, <code class="docutils literal"><span class="pre">/usr/local/cuda</span></code>,
is the most convenient since parts of the <em>NengoGPU</em> implementation
assume it will be there
(however, we can change these assumptions by changing some text files,
so take note of where you install it).</p>
</li>
<li><p class="first">At the end, the installer gives a message
instructing you to set the values
of certain environment variables.
Be sure to do this.
The best way to do it permanently is to set them
in your <code class="docutils literal"><span class="pre">~/.bashrc</span></code> file.
For example, to change the <code class="docutils literal"><span class="pre">PATH</span></code> variable to include
the path to the <code class="docutils literal"><span class="pre">bin</span></code> directory of the CUDA installation,
add the following lines to the end of your <code class="docutils literal"><span class="pre">~/.bashrc</span></code></p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span>PATH=$PATH:&lt;path-to-cuda-bin-dir&gt;
export PATH
</pre></div>
</div>
<p>and then restart your shell.
You can type <code class="docutils literal"><span class="pre">echo</span> <span class="pre">$PATH</span></code> to see
whether the changes have taken effect.</p>
</li>
</ol>
</div>
<div class="section" id="install-cuda-code-samples-optional">
<h2>3: Install CUDA code samples (optional)<a class="headerlink" href="#install-cuda-code-samples-optional" title="Permalink to this headline">¶</a></h2>
<p>This step is not strictly necessary,
but can help to ensure that your driver
is installed properly and that CUDA code has access to the GPU.
It can also be useful in troubleshooting other problems.</p>
<ol class="arabic">
<li><p class="first">Be sure you have downloaded the <a class="reference external" href="http://developer.nvidia.com/cuda-toolkit-40">CUDA code sample installer</a>
for your system. Note where the file gets downloaded.</p>
</li>
<li><p class="first">Run the installer with</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">sudo</span> <span class="n">sh</span> <span class="o">&lt;</span><span class="n">samples</span><span class="o">-</span><span class="n">installer</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>Your home directory is generally a good place to install it.
The installer creates a folder called
<code class="docutils literal"><span class="pre">NVIDA_GPU_Computing_SDK</span></code> in the location you chose.
<code class="docutils literal"><span class="pre">NVIDIA_GPU_COMPUTING_SDK/C/src</span></code> contains a series of subdirectories,
each of which contains CUDA source code
which can be compiled into binary files and then executed.</p>
</li>
<li><p class="first"><code class="docutils literal"><span class="pre">cd</span></code> into <code class="docutils literal"><span class="pre">NVIDA_GPU_Computing_SDK/C</span></code>
and enter the command <code class="docutils literal"><span class="pre">make</span></code>.
This will compile the many CUDA source code samples
in the <code class="docutils literal"><span class="pre">C/src</span></code> directory,
creating a series of executable binaries in <code class="docutils literal"><span class="pre">C/bin/linux/release</span></code>.
Sometimes <code class="docutils literal"><span class="pre">make</span></code> may fail to compile one of the programs,
which will halt the entire compilation process.
Thus, all programs which would have been compiled
after the failed program will remain uncompiled.
To get around this,
you can either fix the compilation issues with the failed program,
or you can compile each individual code sample on its own
(there are a lot of them, so you probably won’t
want to compile <em>all</em> of them this way,
just the ones that seem interesting).
You can <code class="docutils literal"><span class="pre">cd</span></code> into any of the directories
under <code class="docutils literal"><span class="pre">C/src</span></code> and type <code class="docutils literal"><span class="pre">make</span></code> there.
If compilation succeeds,
a binary executable file will be created in <code class="docutils literal"><span class="pre">C/bin/linux/release</span></code>.</p>
</li>
<li><p class="first">To run any sample program, <code class="docutils literal"><span class="pre">cd</span></code> into <code class="docutils literal"><span class="pre">C/bin/linux/release</span></code>
and type <code class="docutils literal"><span class="pre">./&lt;name</span> <span class="pre">of</span> <span class="pre">program&gt;</span></code>.
If the program in question was compiled properly,
you should see a bunch of output
about what computations are being performed,
as well as either a PASS or a FAIL. FAIL’s are bad.</p>
</li>
<li><p class="first">Some useful samples are:</p>
<p><code class="docutils literal"><span class="pre">deviceQueryDrv</span></code>:
Simple test to make sure CUDA programs
have access to the GPU.
Also displays useful information about the CUDA-enabled GPUs on your system
if it can find and access them.</p>
<p><code class="docutils literal"><span class="pre">bandwidthTest</span></code>:
Tests bandwidth between CPU and GPU.
This bandwidth can sometimes be a bottleneck of the <em>NengoGPU</em> implementation.
Online you can usually find bandwidth benchmarks
which say roughly what the bandwidth should be for a given card.
If your bandwidth is much lower than the benchmark for your card,
there may be a problem with your setup.</p>
<p><code class="docutils literal"><span class="pre">simpleMultiGPU</span></code>:
Useful if your system has multiple GPUs.
Tests whether they can all be used together.</p>
</li>
</ol>
</div>
<div class="section" id="install-cula-dense-optional-for-nengoutilsgpu">
<h2>4. Install CULA Dense (optional; for <em>NengoUtilsGPU</em>)<a class="headerlink" href="#install-cula-dense-optional-for-nengoutilsgpu" title="Permalink to this headline">¶</a></h2>
<p>This step is very similar to step 2 (“Install CUDA Toolkit”).</p>
<ol class="arabic">
<li><p class="first">Be sure you have downloaded the <a class="reference external" href="http://developer.nvidia.com/cuda-toolkit-40">CULA toolkit installer</a>
for your system. Note where the file gets downloaded.</p>
</li>
<li><p class="first">Run the installer with</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="n">sudo</span> <span class="n">sh</span> <span class="o">&lt;</span><span class="n">CULA</span><span class="o">-</span><span class="n">installer</span><span class="o">&gt;</span>
</pre></div>
</div>
</li>
<li><p class="first">The installer will ask where you want to install CULA.
Again, the default location <code class="docutils literal"><span class="pre">/usr/local/cula</span></code>
is the most convenient since parts of the GPU implementation
assume it will be there
(however, we can change these assumptions by changing some text files,
so take note of where you install it).</p>
</li>
<li><p class="first">Be sure to set the environment variables
as recommended by the installer.
See “2. Install CUDA Toolkit” for the best way to do this.</p>
</li>
</ol>
</div>
<div class="section" id="compile-the-shared-libraries">
<h2>5. Compile the shared libraries<a class="headerlink" href="#compile-the-shared-libraries" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p class="first"><code class="docutils literal"><span class="pre">cd</span></code> into the directory <code class="docutils literal"><span class="pre">NengoGPU</span></code>.
For developers this is can be found
in <code class="docutils literal"><span class="pre">simulator/src/c/NengoGPU</span></code>.
For users of the prepackaged version of Nengo,
it should just be a subdirectory of the main Nengo folder.</p>
</li>
<li><p class="first">Run <code class="docutils literal"><span class="pre">./configure</span></code> to create the necessary symbolic links
(you may have to <code class="docutils literal"><span class="pre">chmod</span></code> this
to ensure that the permissions are set to execute).</p>
</li>
<li><p class="first">If you installed CUDA in a location other than the default,
open the file <code class="docutils literal"><span class="pre">Makefile</span></code> with your favourite text editor
and edit it so that the variables <code class="docutils literal"><span class="pre">CUDA_INC_PATH</span></code> and <code class="docutils literal"><span class="pre">CUDA_LIB_PATH</span></code>
point to the correct locations.
If you installed CUDA in the default location,
you can skip this step.</p>
</li>
<li><p class="first"><code class="docutils literal"><span class="pre">nvcc</span></code>, the CUDA compiler, is incompatible
with versions of gcc that are too new,
where “too new” is a function of the <code class="docutils literal"><span class="pre">nvcc</span></code> version.
<code class="docutils literal"><span class="pre">gcc-4.4</span></code> is generally a safe bet.
Install it with <code class="docutils literal"><span class="pre">sudo</span> <span class="pre">apt-get</span> <span class="pre">install</span> <span class="pre">gcc-4.4</span></code>.
If you have gcc-4.4 installed in some directory
other than the default (<code class="docutils literal"><span class="pre">/usr/bin</span></code>),
then you have to edit the <code class="docutils literal"><span class="pre">GCC_PATH</span></code> variable
in the NengoGPU <code class="docutils literal"><span class="pre">Makefile</span></code> to point there.</p>
</li>
<li><p class="first">Type <code class="docutils literal"><span class="pre">make</span></code> to compile the code in the directory.
If successful, this creates a shared library called <code class="docutils literal"><span class="pre">libNengoGPU.so</span></code>.
This is the native library that Nengo will call
to perform the neural simulations on the GPU.</p>
</li>
<li><p class="first"><em>Optional; for NengoUtilsGPU</em></p>
<p>Redo steps 1–3 in the <code class="docutils literal"><span class="pre">NengoUtilsGPU</span></code> directory,
which should be located in the same directory as the <code class="docutils literal"><span class="pre">NengoGPU</span></code> directory.
In this case, there are two additional variables
in the <code class="docutils literal"><span class="pre">Makefile</span></code> that you might have to edit
which point to CULA libraries and include files:
<code class="docutils literal"><span class="pre">CULA_INC_PATH</span></code> and <code class="docutils literal"><span class="pre">CULA_LIB_PATH</span></code>.
Again, you only have to edit these if you installed CULA
in a location other than the default.</p>
</li>
<li><p class="first">We have make sure that the CUDA libraries,
which are referenced by <code class="docutils literal"><span class="pre">libNengoGPU.so</span></code>,
can be found at runtime.
To acheive this, <code class="docutils literal"><span class="pre">cd</span></code> into <code class="docutils literal"><span class="pre">/etc/ld.so.conf.d/</span></code>.
Using your favourite text editor and ensuring you have root privileges,
create a text file called <code class="docutils literal"><span class="pre">cuda.conf</span></code> (do e.g. <code class="docutils literal"><span class="pre">sudo</span> <span class="pre">nano</span> <span class="pre">cuda.conf</span></code>).
In this file type the lines</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">absolute</span><span class="o">-</span><span class="n">path</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">CUDA</span><span class="o">-</span><span class="nb">dir</span><span class="o">&gt;/</span><span class="n">lib</span><span class="o">/</span>
<span class="o">&lt;</span><span class="n">absolute</span><span class="o">-</span><span class="n">path</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">CUDA</span><span class="o">-</span><span class="nb">dir</span><span class="o">&gt;/</span><span class="n">lib64</span><span class="o">/</span>
</pre></div>
</div>
<p>For example, if you installed CUDA in the default location you should have</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">cuda</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span>
<span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">cuda</span><span class="o">/</span><span class="n">lib64</span><span class="o">/</span>
</pre></div>
</div>
<p>Save the file and exit.</p>
</li>
<li><p class="first"><em>Optional; for NengoUtilsGPU</em></p>
<p>If you are installing <em>NengoUtilsGPU</em> as well,
edit the <code class="docutils literal"><span class="pre">/etc/ld.so.conf.d/cuda.conf</span></code> file
to also include the following lines</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">absolute</span><span class="o">-</span><span class="n">path</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">CULA</span><span class="o">-</span><span class="nb">dir</span><span class="o">&gt;/</span><span class="n">lib</span><span class="o">/</span>
<span class="o">&lt;</span><span class="n">absolute</span><span class="o">-</span><span class="n">path</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">CULA</span><span class="o">-</span><span class="nb">dir</span><span class="o">&gt;/</span><span class="n">lib64</span><span class="o">/</span>
</pre></div>
</div>
</li>
<li><p class="first">Run <code class="docutils literal"><span class="pre">sudo</span> <span class="pre">ldconfig</span></code>.
This populates the file <code class="docutils literal"><span class="pre">/etc/ld.so.cache</span></code> using the files
in <code class="docutils literal"><span class="pre">/etc/ld.so.conf.d/</span></code>.
<code class="docutils literal"><span class="pre">ld.so.cache</span></code> tells the machine
where to look for shared libraries at runtime
(in addition to the default locations
like <code class="docutils literal"><span class="pre">/usr/lib</span></code> and <code class="docutils literal"><span class="pre">/usr/local/lib</span></code>).</p>
</li>
<li><p class="first"><em>Optional; for developers</em></p>
<p>The Java Virtual Machine has to be told
where to look for native libraries.
Edit the JVM arguments in your Eclipse Run and Debug configurations
so that they contains the following text</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">-</span><span class="n">Djava</span><span class="o">.</span><span class="n">library</span><span class="o">.</span><span class="n">path</span><span class="o">=&lt;</span><span class="n">absolute</span><span class="o">-</span><span class="n">path</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">NengoGPU</span><span class="o">-</span><span class="nb">dir</span><span class="o">&gt;</span>
</pre></div>
</div>
<p><em>Optional; for NengoUtilsGPU</em>
If you are also installing NengoUtilsGPU, then you should instead add</p>
<div class="code bash highlight-default"><div class="highlight"><pre><span></span><span class="o">-</span><span class="n">Djava</span><span class="o">.</span><span class="n">library</span><span class="o">.</span><span class="n">path</span><span class="o">=&lt;</span><span class="n">absolute</span><span class="o">-</span><span class="n">path</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">NengoGPU</span><span class="o">-</span><span class="nb">dir</span><span class="o">&gt;</span><span class="p">:</span><span class="o">&lt;</span><span class="n">absolute</span><span class="o">-</span><span class="n">path</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">NengoUtilsGPU</span><span class="o">-</span><span class="nb">dir</span><span class="o">&gt;</span>
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="using-nengogpu-and-nengoutilsgpu">
<h2>6. Using NengoGPU and NengoUtilsGPU<a class="headerlink" href="#using-nengogpu-and-nengoutilsgpu" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p class="first">Open up Nengo.
Click on the icon on the right side
of the tool bar at the top of the Nengo GUI.
This will open up a menu
which lets you configure the parallelization of Nengo.</p>
</li>
<li><p class="first">If the previous steps worked properly,
then the field “Number of GPUs for Simulation” will be enabled
and you will be able to choose the number of GPUs
to use for Nengo simulations.
This field will not let you choose more GPUs
than Nengo can detect on your system.
If the <code class="docutils literal"><span class="pre">libNengoGPU</span></code> library wasn’t found
(either because building it didn’t succeed
or Java doesn’t know where to find it)
or no CUDA enabled GPUs can be detected on your system,
then this field will be grayed out
and an error message will appear to the right of the field.
In this case, revisit the relevant steps above.</p>
</li>
<li><p class="first">After setting the “Number of GPUs for Simulation” field
to a non-zero value,
any simulations you run that contain NEF Ensembles
should run those NEF Ensembles on the GPU!
There should be no change at all
in the way you simulate networks except,
of course, that they will run faster.
You can still set probes, collect spikes, etc.
in the same way you did before.</p>
</li>
<li><p class="first"><em>NengoGPU</em> provides support for running
certain NEF Ensembles on the CPU
while the rest are simulated on GPUs.
Right-click on the NEF Ensembles
that you want to stay on the CPU
and select the “configure” option.
Set the <code class="docutils literal"><span class="pre">useGPU</span></code> field to false,
and the ensemble you are configuring
will run on the CPU no matter what.
You can also edit the same field on a Network object,
and it will force all NEF Ensembles
within the Network to run on the CPU.</p>
</li>
<li><p class="first">You can also set the number of GPUs
to use for simulation in a script.
This is useful if you want to ensure that a given network,
created by a script (and maybe even run in that script)
always runs with the same number of devices.
To achieve this, add the following line to your script:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">ca</span><span class="o">.</span><span class="n">nengo</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">impl</span><span class="o">.</span><span class="n">NEFGPUInterface</span><span class="o">.</span><span class="n">setRequestedNumDevices</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal"><span class="pre">x</span></code> is the number of devices
you want to use for the resulting network.</p>
</li>
<li><p class="first">GPU simulations can be combined with CPU multithreading.
In the parallelization dialog,
you can select the number of CPU threads to use.
All NEF Ensembles that are set to run on the GPU will run there,
and the rest of the nodes in the Network
will be parallelized via multithreading.
This is especially useful for speeding up SimpleNodes
that do a lot of computation.
The optimal number of threads will vary greatly
depending on the particular network you are running
and the specs of your machine,
and generally takes some experimentation to get right.
However, using a number of threads equivalent
to the number of cores on your machine
is usually a good place to start.</p>
</li>
<li><p class="first"><em>Optional; for NengoUtilsGPU</em></p>
<p>If you installed <code class="docutils literal"><span class="pre">libNengoUtilsGPU</span></code> and it succeeded,
then the parallelization dialog will have
the “Use GPU for Ensemble Creation” checkbox enabled.
If you check the box and press OK,
then all NEF Ensembles you create afterwards
will use the GPU for Singular Value Decomposition,
and this process should be significantly faster,
especially for larger ensembles.
If the install failed,
Nengo cannot detect a CUDA-enabled GPU,
or you simply chose not to install NengoUtilsGPU,
then the box will be disabled
and an error message will appear to its right.</p>
<p>Note that the SVD implementation
cannot take advantage of multiple GPUs,
which is why there is no option to select
the number of GPUs for ensemble creation.
To change whether a GPU is used for ensemble creation from a script,
use the line:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">ca</span><span class="o">.</span><span class="n">nengo</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">impl</span><span class="o">.</span><span class="n">WeightedCostApproximator</span><span class="o">.</span><span class="n">setUseGPU</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal"><span class="pre">x</span></code> is either <code class="docutils literal"><span class="pre">True</span></code> or <code class="docutils literal"><span class="pre">False</span></code>.</p>
</li>
</ol>
</div>
</div>


          </div>
            
  <div class="footer-relations">
    
      <div class="pull-left">
        <a class="btn btn-default" href="large_ensembles.html" title="previous chapter (use the left arrow)">Generating large ensembles</a>
      </div>
    
      <div class="pull-right">
        <a class="btn btn-default" href="ipython_notebook.html" title="next chapter (use the right arrow)">Integrating with IPython Notebook</a>
      </div>
    </div>
    <div class="clearer"></div>
  
        </div>
        <div class="clearfix"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="ipython_notebook.html" title="Integrating with IPython Notebook"
             >next</a> |</li>
        <li class="right" >
          <a href="large_ensembles.html" title="Generating large ensembles"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Nengo 1.4 1.4 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" >Advanced usage</a> &#187;</li> 
      </ul>
    </div>
  <script type="text/javascript">
    $(document).ready(function() {
      $(".toggle > *").hide();
      $(".toggle .header").show();
      $(".toggle .header").click(function() {
        $(this).parent().children().not(".header").toggle(400);
        $(this).parent().children(".header").toggleClass("open");
      });
    });
  </script>

<script type="text/javascript">
  $("#mobile-toggle a").click(function () {
    $("#left-column").toggle();
  });
</script>
<script type="text/javascript" src="../_static/js/bootstrap.js"></script>
  <div class="footer">
    &copy; Copyright 2006-2017, Bryan Tripp & Centre for Theoretical Neuroscience, University of Waterloo. Created using <a href="http://sphinx.pocoo.org/">Sphinx</a>.
  </div>
  </body>
</html>